#!/usr/bin/env python3
"""
LibChat - æœ¬åœ°Pythonåº“æ™ºèƒ½é—®ç­”ç³»ç»Ÿ

è¿™æ˜¯ä¸€ä¸ªåŸºäºRAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰æŠ€æœ¯çš„å‘½ä»¤è¡Œåº”ç”¨ï¼Œèƒ½å¤Ÿå¯¹æœ¬åœ°å®‰è£…çš„Pythonåº“è¿›è¡Œæ™ºèƒ½é—®ç­”ã€‚
ç³»ç»Ÿé€šè¿‡ASTè§£æã€å‘é‡ç´¢å¼•ã€é‡æ’åºå’Œå¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆï¼Œæä¾›å‡†ç¡®çš„ä»£ç ç›¸å…³é—®ç­”æœåŠ¡ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
1. buildå‘½ä»¤ï¼šæ„å»ºæŒ‡å®šPythonåº“çš„çŸ¥è¯†åº“ç´¢å¼•
2. askå‘½ä»¤ï¼šåŸºäºæ„å»ºçš„çŸ¥è¯†åº“å›ç­”ç”¨æˆ·é—®é¢˜

ä½œè€…ï¼šLibChat Team
ç‰ˆæœ¬ï¼š1.0.0
"""

import os
import sys
import logging
import json
from pathlib import Path
from typing import List, Optional
import typer
from rich.console import Console
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, TextColumn
from rich.markdown import Markdown
from openai import OpenAI
from loguru import logger
from dotenv import load_dotenv

# å¯¼å…¥llama_indexç›¸å…³æ¨¡å—
from llama_index.core import VectorStoreIndex, StorageContext
from llama_index.vector_stores.faiss import FaissVectorStore
from llama_index.core.retrievers import VectorIndexRetriever

# å¯¼å…¥OpenAIç›¸å…³æ¨¡å—
import openai
from openai import OpenAI

# å¯¼å…¥æˆ‘ä»¬è‡ªå®šä¹‰çš„æ¨¡å—
from src.source_inspector.inspector import PackageInspector
from src.chunker.ast_chunker import ASTChunker
from src.indexing.fixed_indexer import FixedIndexer
from src.reranking.reranker import SentenceTransformerReranker

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# åˆ›å»ºCLIåº”ç”¨å’Œæ§åˆ¶å°
app = typer.Typer(
name="libchat",
    help="æœ¬åœ°Pythonåº“æ™ºèƒ½é—®ç­”ç³»ç»Ÿ - åŸºäºRAGæŠ€æœ¯çš„ä»£ç é—®ç­”åŠ©æ‰‹",
    add_completion=False
)
console = Console()

# é…ç½®å¸¸é‡
CONFIG = {
    "embedding_model": os.getenv("EMBEDDING_MODEL", "BAAI/bge-small-en-v1.5"),
    "reranker_model": os.getenv("RERANKER_MODEL", "BAAI/bge-reranker-large"), 
    "qwen_model": "qwen-turbo",
    "qwen_api_key": os.getenv("QWEN_API_KEY"),
    "qwen_base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
    "index_dir": "./indexes",
    "top_k_retrieval": 20,
    "top_k_rerank": 5,
    "max_tokens": 1024,
    "temperature": 0.1
}

# é…ç½®æ—¥å¿—
logger.remove()
logger.add(
    sys.stderr,
    format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>",
    level="INFO"
)
logger.add(
    "logs/libchat.log",
    format="{time:YYYY-MM-DD HH:mm:ss} | {level: <8} | {name}:{function}:{line} - {message}",
    level="DEBUG",
    rotation="10 MB"
)


def ensure_directories() -> None:
    """ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨ã€‚"""
    Path(CONFIG["index_dir"]).mkdir(exist_ok=True)
    Path("logs").mkdir(exist_ok=True)


def process_query(query: str, index_path: str) -> str:
    """
    å¤„ç†ç”¨æˆ·æŸ¥è¯¢ï¼Œæ‰§è¡Œå®Œæ•´çš„RAGæµç¨‹ã€‚
    
    Args:
        query: ç”¨æˆ·æŸ¥è¯¢
        index_path: ç´¢å¼•è·¯å¾„
        
    Returns:
        ç”Ÿæˆçš„ç­”æ¡ˆ
    """
    try:
        # 1. åŠ è½½ç´¢å¼•
        logger.info(f"æ­£åœ¨åŠ è½½ç´¢å¼•: {index_path}")
        indexer = FixedIndexer(index_dir=CONFIG["index_dir"])
        index_name = Path(index_path).name
        index = indexer.load_index(index_name, embedding_model=CONFIG["embedding_model"])
        
        if index is None:
            logger.error(f"æ— æ³•åŠ è½½ç´¢å¼•: {index_name}")
            return f"æŠ±æ­‰ï¼Œæ— æ³•åŠ è½½ç´¢å¼• '{index_name}'ã€‚è¯·ç¡®ä¿ç´¢å¼•å·²æ­£ç¡®æ„å»ºã€‚"
        
        # 2. æ£€ç´¢ç›¸å…³æ–‡æ¡£
        logger.info(f"æ­£åœ¨æ£€ç´¢æŸ¥è¯¢: {query}")
        retriever = VectorIndexRetriever(
            index=index,
            similarity_top_k=CONFIG["top_k_retrieval"]
        )
        retrieved_nodes = retriever.retrieve(query)
        
        if not retrieved_nodes:
            return "æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰æ‰¾åˆ°ä¸æ‚¨çš„é—®é¢˜ç›¸å…³çš„ä¿¡æ¯ã€‚"
        
        logger.info(f"æ£€ç´¢åˆ° {len(retrieved_nodes)} ä¸ªç›¸å…³æ–‡æ¡£")
        
        # 3. é‡æ’åºï¼ˆå¦‚æœæœ‰è¶³å¤Ÿçš„æ–‡æ¡£ï¼‰
        if len(retrieved_nodes) > CONFIG["top_k_rerank"]:
            logger.info("æ­£åœ¨è¿›è¡Œé‡æ’åº...")
            reranker = SentenceTransformerReranker(
                 model_name=CONFIG["reranker_model"],
                 top_n=CONFIG["top_k_rerank"]
             )
            
            # å‡†å¤‡é‡æ’åºçš„æ–‡æ¡£
            documents = [node.text for node in retrieved_nodes]
            reranked_docs = reranker.rerank(query, documents)
            
            # ä½¿ç”¨é‡æ’åºåçš„æ–‡æ¡£ï¼ˆreranked_docsç›´æ¥æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨ï¼‰
            context_texts = reranked_docs
            logger.info(f"é‡æ’åºåä¿ç•™ {len(context_texts)} ä¸ªæœ€ç›¸å…³æ–‡æ¡£")
        else:
            # å¦‚æœæ–‡æ¡£æ•°é‡ä¸å¤šï¼Œç›´æ¥ä½¿ç”¨æ£€ç´¢ç»“æœ
            context_texts = [node.text for node in retrieved_nodes]
            logger.info(f"ç›´æ¥ä½¿ç”¨ {len(context_texts)} ä¸ªæ£€ç´¢æ–‡æ¡£")
        
        # 4. æ„å»ºä¸Šä¸‹æ–‡
        context = "\n\n".join(context_texts)
        
        # 5. ç”Ÿæˆç­”æ¡ˆ
        logger.info("æ­£åœ¨ç”Ÿæˆç­”æ¡ˆ...")
        answer = generate_answer_with_llm(query, context)
        
        return answer
        
    except Exception as e:
        logger.error(f"å¤„ç†æŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
        return f"å¤„ç†æŸ¥è¯¢æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"


def generate_answer_with_llm(query: str, context: str) -> str:
    """
    ä½¿ç”¨Qwen APIåŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆç­”æ¡ˆã€‚
    
    Args:
        query: ç”¨æˆ·æŸ¥è¯¢
        context: æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡
        
    Returns:
        ç”Ÿæˆçš„ç­”æ¡ˆ
    """
    try:
        # åˆå§‹åŒ–Qwenå®¢æˆ·ç«¯ï¼ˆä½¿ç”¨OpenAIå…¼å®¹æ¥å£ï¼‰
        client = OpenAI(
            api_key=CONFIG["qwen_api_key"],
            base_url=CONFIG["qwen_base_url"]
        )
        
        # æ„å»ºæ¶ˆæ¯
        messages = [
            {
                "role": "system",
                "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Pythonä»£ç åŠ©æ‰‹ã€‚è¯·åŸºäºæä¾›çš„ä»£ç ä¸Šä¸‹æ–‡å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚æä¾›å‡†ç¡®ã€è¯¦ç»†çš„ç­”æ¡ˆï¼Œå¦‚æœå¯èƒ½çš„è¯ï¼ŒåŒ…å«ç›¸å…³çš„ä»£ç ç¤ºä¾‹ã€‚å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰è¶³å¤Ÿçš„ä¿¡æ¯æ¥å›ç­”é—®é¢˜ï¼Œè¯·è¯šå®åœ°è¯´æ˜ã€‚"
            },
            {
                "role": "user",
                "content": f"""ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
                {context}

                ç”¨æˆ·é—®é¢˜ï¼š{query}

                è¯·åŸºäºä¸Šè¿°ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ã€‚"""
            }
        ]
        
        # æ‰“å°å®Œæ•´çš„æç¤ºè¯åˆ°æ—¥å¿—
        logger.info(f"æ„å»ºçš„æç¤ºè¯ï¼ˆPromptï¼‰: {json.dumps(messages, indent=2, ensure_ascii=False)}")

        # è°ƒç”¨Qwen API
        logger.info(f"æ­£åœ¨è°ƒç”¨Qwen API ({CONFIG['qwen_model']})...")
        response = client.chat.completions.create(
            model=CONFIG["qwen_model"],
            messages=messages,
            max_tokens=CONFIG["max_tokens"],
            temperature=CONFIG["temperature"]
        )
        
        answer = response.choices[0].message.content.strip()
        logger.info("Qwen APIè°ƒç”¨æˆåŠŸ")
        
        return answer if answer else "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•åŸºäºæä¾›çš„ä¸Šä¸‹æ–‡ç”Ÿæˆåˆé€‚çš„ç­”æ¡ˆã€‚"
        
    except Exception as e:
        error_msg = str(e)
        logger.error(f"Qwen APIè°ƒç”¨å¤±è´¥: {e}")
        logger.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
        logger.error(f"é”™è¯¯è¯¦æƒ…: {error_msg}")
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯é…é¢ä¸è¶³çš„é”™è¯¯
        if "429" in error_msg or "quota" in error_msg.lower() or "insufficient_quota" in error_msg.lower():
            logger.warning("Qwen APIé…é¢ä¸è¶³ï¼Œè¯·æ£€æŸ¥æ‚¨çš„è®¡è´¹è¯¦æƒ…")
            quota_msg = "\nâš ï¸  Qwen APIé…é¢ä¸è¶³æç¤ºï¼š\n" + \
                       "æ‚¨çš„Qwen APIé…é¢å·²ç”¨å®Œã€‚è¯·è®¿é—®é˜¿é‡Œäº‘æ§åˆ¶å°æ£€æŸ¥æ‚¨çš„è®¡è´¹è¯¦æƒ…ã€‚\n" + \
                       "ç°åœ¨å°†ä½¿ç”¨ç®€å•çš„åŸºäºæ£€ç´¢çš„ç­”æ¡ˆç”Ÿæˆã€‚\n"
            simple_answer = generate_simple_answer(query, context)
            return quota_msg + simple_answer
        
        logger.info("å›é€€åˆ°ç®€å•ç­”æ¡ˆç”Ÿæˆ...")
        return generate_simple_answer(query, context)


def generate_simple_answer(query: str, context: str) -> str:
    """
    å½“LLMä¸å¯ç”¨æ—¶çš„ç®€å•ç­”æ¡ˆç”Ÿæˆå¤‡ç”¨æ–¹æ¡ˆã€‚
    
    Args:
        query: ç”¨æˆ·æŸ¥è¯¢
        context: æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡
        
    Returns:
        åŸºäºæ£€ç´¢ç»“æœçš„ç®€å•ç­”æ¡ˆ
    """
    # ç®€å•çš„åŸºäºå…³é”®è¯åŒ¹é…çš„ç­”æ¡ˆç”Ÿæˆ
    lines = context.split('\n')
    relevant_lines = []
    
    query_words = query.lower().split()
    
    for line in lines:
        if any(word in line.lower() for word in query_words):
            relevant_lines.append(line.strip())
    
    if relevant_lines:
        answer = "åŸºäºæ£€ç´¢åˆ°çš„ä»£ç ï¼Œä»¥ä¸‹æ˜¯ç›¸å…³ä¿¡æ¯ï¼š\n\n"
        answer += "\n".join(relevant_lines[:5])  # é™åˆ¶æ˜¾ç¤ºå‰5è¡Œ
        if len(relevant_lines) > 5:
            answer += "\n\n...ï¼ˆè¿˜æœ‰æ›´å¤šç›¸å…³å†…å®¹ï¼‰"
    else:
        answer = "æŠ±æ­‰ï¼Œæˆ‘åœ¨æ£€ç´¢åˆ°çš„ä»£ç ä¸­æ²¡æœ‰æ‰¾åˆ°ä¸æ‚¨é—®é¢˜ç›´æ¥ç›¸å…³çš„ä¿¡æ¯ã€‚\n\næ£€ç´¢åˆ°çš„éƒ¨åˆ†å†…å®¹ï¼š\n\n"
        answer += context[:500] + "..." if len(context) > 500 else context
    
    return answer


@app.command("test", help="è¿è¡Œå®Œæ•´çš„ç«¯åˆ°ç«¯æµ‹è¯•")
def run_test(
    package_name: str = typer.Option("typer", "--package", "-p", help="ç”¨äºæµ‹è¯•çš„åŒ…å"),
    query: str = typer.Option("å¦‚ä½•åˆ›å»ºä¸€ä¸ªCLIåº”ç”¨ç¨‹åºï¼Ÿ", "--query", "-q", help="ç”¨äºæµ‹è¯•çš„æŸ¥è¯¢")
) -> None:
    """æ‰§è¡Œå®Œæ•´çš„ç«¯åˆ°ç«¯æµ‹è¯•ã€‚"""
    console.print(Panel(f"[bold green]å¼€å§‹ç«¯åˆ°ç«¯æµ‹è¯•[/bold green]", title="æµ‹è¯•æµç¨‹", expand=False))
    
    # 1. å¼ºåˆ¶é‡å»ºç´¢å¼•
    test_index_name = "test_index"
    console.print(f"[cyan]æ­¥éª¤ 1: å¼ºåˆ¶é‡å»ºç´¢å¼• '{test_index_name}' (ä½¿ç”¨åŒ…: {package_name})[/cyan]")
    build_index(package_name, test_index_name, force_rebuild=True)
    
    # 2. ä½¿ç”¨æµ‹è¯•æŸ¥è¯¢æé—®
    console.print(f"[cyan]æ­¥éª¤ 2: ä½¿ç”¨æµ‹è¯•æŸ¥è¯¢æé—®[/cyan]")
    console.print(f"[yellow]æŸ¥è¯¢:[/yellow] {query}")
    ask_question(query, test_index_name)
    
    console.print(Panel(f"[bold green]ç«¯åˆ°ç«¯æµ‹è¯•å®Œæˆ[/bold green]", title="æµ‹è¯•æµç¨‹", expand=False))

@app.command("build", help="æ„å»ºæŒ‡å®šPythonåº“çš„çŸ¥è¯†åº“ç´¢å¼•")
def build_index(
    package_name: str = typer.Argument(..., help="è¦ç´¢å¼•çš„PythonåŒ…çš„åç§°"),
    index_name: str = typer.Option("default", "--index", "-i", help="è¦åˆ›å»ºçš„ç´¢å¼•çš„åç§°"),
    force_rebuild: bool = typer.Option(False, "--force", "-f", help="å¼ºåˆ¶é‡æ–°æ„å»ºç´¢å¼•"),
    package_path: Optional[str] = typer.Option(None, "--path", "-p", help="æ‰‹åŠ¨æŒ‡å®šåŒ…çš„ç‰©ç†è·¯å¾„")
) -> None:
    """
    æ„å»ºæŒ‡å®šPythonåº“çš„çŸ¥è¯†åº“ç´¢å¼•ã€‚
    
    è¯¥å‘½ä»¤ä¼šï¼š
    1. æ£€æŸ¥å¹¶è·å–æŒ‡å®šåŒ…çš„æ‰€æœ‰æºæ–‡ä»¶
    2. ä½¿ç”¨ASTè§£æå™¨å¯¹æºä»£ç è¿›è¡Œç»“æ„åŒ–åˆ†å—
    3. åˆ›å»ºå‘é‡ç´¢å¼•å¹¶ä¿å­˜åˆ°æœ¬åœ°
    
    Args:
        package_name: PythonåŒ…åç§°ï¼ˆå¦‚ 'numpy', 'pandas' ç­‰ï¼‰
        force: æ˜¯å¦å¼ºåˆ¶é‡æ–°æ„å»ºç´¢å¼•
    """
    ensure_directories()

    # ä½¿ç”¨åŒ…åä½œä¸ºä»£ç åº“è·¯å¾„
    repo_path = package_name
    index_dir = Path(CONFIG["index_dir"])

    console.print(Panel.fit(
        f"[bold blue]å¼€å§‹ä¸º '{repo_path}' æ„å»ºçŸ¥è¯†åº“ç´¢å¼• (åç§°: {index_name})[/bold blue]",
        border_style="blue"
    ))

    try:
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console
        ) as progress:
            task_build_index = progress.add_task("æ­£åœ¨åˆ›å»ºå¹¶æŒä¹…åŒ–å‘é‡ç´¢å¼•...", total=None)
            logger.info(f"å¼€å§‹ä¸ºä»£ç åº“ '{repo_path}' æ„å»ºç´¢å¼• '{index_name}'")

            indexer = FixedIndexer(index_dir=str(index_dir))

            # è°ƒç”¨ FixedIndexer çš„ rebuild_index æ–¹æ³•
            success = indexer.rebuild_index(
                repo_path, 
                index_name=index_name, 
                embedding_model=CONFIG["embedding_model"],
                package_path=package_path
            )

            if not success:
                console.print("[red]é”™è¯¯ï¼šæ„å»ºç´¢å¼•å¤±è´¥ã€‚[/red]")
                raise typer.Exit(code=1)

            progress.update(task_build_index, description="ç´¢å¼•åˆ›å»ºå®Œæˆ")
            final_index_path = index_dir / index_name
            logger.info(f"ç´¢å¼•å·²ä¿å­˜åˆ° {final_index_path}")

        console.print(Panel.fit(
            f"[bold green]âœ… æˆåŠŸä¸º '{repo_path}' æ„å»ºçŸ¥è¯†åº“ç´¢å¼•ï¼[/bold green]\n"
            f"ğŸ“ ç´¢å¼•åç§°: {index_name}\n"
            f"ğŸ“ å­˜å‚¨ä½ç½®: {final_index_path}",
            border_style="green",
            title="æ„å»ºå®Œæˆ"
        ))
        
    except Exception as e:
        console.print(f"[red]æ„å»ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}[/red]")
        logger.error(f"æ„å»ºç´¢å¼•å¤±è´¥: {e}", exc_info=True)
        raise e


@app.command("ask", help="åŸºäºæ„å»ºçš„çŸ¥è¯†åº“å›ç­”ç”¨æˆ·é—®é¢˜")
def ask_question(
    query: str = typer.Argument(..., help="æ‚¨è¦æå‡ºçš„é—®é¢˜"),
    index_name: str = typer.Option("default", "--index", "-i", help="è¦ä½¿ç”¨çš„ç´¢å¼•åç§°")
) -> None:
    """å¤„ç†ç”¨æˆ·æŸ¥è¯¢å¹¶æ‰“å°ç­”æ¡ˆã€‚"""
    ensure_directories()
    index_path = Path(CONFIG["index_dir"]) / index_name

    if not index_path.exists():
        console.print(f"[red]é”™è¯¯ï¼šç´¢å¼• '{index_name}' ä¸å­˜åœ¨ã€‚è¯·å…ˆä½¿ç”¨ 'build' å‘½ä»¤æ„å»ºå®ƒã€‚[/red]")
        raise typer.Exit(code=1)

    console.print(Panel.fit(
        f"[bold blue]æ­£åœ¨ä½¿ç”¨ç´¢å¼• '{index_name}' å›ç­”é—®é¢˜[/bold blue]",
        border_style="blue"
    ))

    try:
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console
        ) as progress:
            task = progress.add_task("æ­£åœ¨ç”Ÿæˆç­”æ¡ˆ...", total=None)
            answer = process_query(query, str(index_path))
            progress.update(task, description="ç­”æ¡ˆç”Ÿæˆå®Œæˆ")
        
        console.print(Markdown(f"**ä½ é—®**ï¼š{query}\n\n**å›ç­”**ï¼š{answer}"))
    except Exception as e:
        console.print(f"[red]å¤„ç†æŸ¥è¯¢æ—¶å‘ç”Ÿé”™è¯¯: {e}[/red]")
        logger.error(f"æŸ¥è¯¢å¤„ç†å¤±è´¥: {e}", exc_info=True)

if __name__ == "__main__":
    app()