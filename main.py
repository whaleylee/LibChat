#!/usr/bin/env python3
"""
LibChat - æœ¬åœ°Pythonåº“æ™ºèƒ½é—®ç­”ç³»ç»Ÿ

è¿™æ˜¯ä¸€ä¸ªåŸºäºRAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰æŠ€æœ¯çš„å‘½ä»¤è¡Œåº”ç”¨ï¼Œèƒ½å¤Ÿå¯¹æœ¬åœ°å®‰è£…çš„Pythonåº“è¿›è¡Œæ™ºèƒ½é—®ç­”ã€‚
ç³»ç»Ÿé€šè¿‡ASTè§£æã€å‘é‡ç´¢å¼•ã€é‡æ’åºå’Œå¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆï¼Œæä¾›å‡†ç¡®çš„ä»£ç ç›¸å…³é—®ç­”æœåŠ¡ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
1. buildå‘½ä»¤ï¼šæ„å»ºæŒ‡å®šPythonåº“çš„çŸ¥è¯†åº“ç´¢å¼•
2. askå‘½ä»¤ï¼šåŸºäºæ„å»ºçš„çŸ¥è¯†åº“å›ç­”ç”¨æˆ·é—®é¢˜

ä½œè€…ï¼šLibChat Team
ç‰ˆæœ¬ï¼š1.0.0
"""

import os
import sys
import logging
import json
from pathlib import Path

# è§£å†³Windowsä¸Šrichåº“çš„UnicodeEncodeError
# åœ¨Windowsä¸Šï¼Œé€šè¿‡è®¾ç½®ç¯å¢ƒå˜é‡å¼ºåˆ¶ä½¿ç”¨UTF-8ç¼–ç 
if sys.platform == "win32":
    os.environ["PYTHONIOENCODING"] = "utf-8"
from typing import List, Optional
import typer
from rich.console import Console
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, TextColumn
from rich.markdown import Markdown
from openai import OpenAI
from loguru import logger
from dotenv import load_dotenv

# å¯¼å…¥llama_indexç›¸å…³æ¨¡å—
from llama_index.core import VectorStoreIndex, StorageContext
from llama_index.vector_stores.faiss import FaissVectorStore
from llama_index.core.retrievers import VectorIndexRetriever

# å¯¼å…¥OpenAIç›¸å…³æ¨¡å—
import openai
from openai import OpenAI

# å¯¼å…¥æˆ‘ä»¬è‡ªå®šä¹‰çš„æ¨¡å—
from src.source_inspector.inspector import PackageInspector
from src.chunker.ast_chunker import ASTChunker
from src.indexing.fixed_indexer import FixedIndexer
from src.indexing.indexer import save_knowledge_graph, load_knowledge_graph
from src.reranking.reranker import SentenceTransformerReranker
from src.retrieval.graph_retriever import GraphRAGRetriever
from src.github_crawler.github_crawler import GitHubCrawler

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# åˆ›å»ºCLIåº”ç”¨å’Œæ§åˆ¶å°
app = typer.Typer(
name="libchat",
    help="æœ¬åœ°Pythonåº“æ™ºèƒ½é—®ç­”ç³»ç»Ÿ - åŸºäºRAGæŠ€æœ¯çš„ä»£ç é—®ç­”åŠ©æ‰‹",
    add_completion=False
)


# é…ç½®å¸¸é‡
CONFIG = {
    "embedding_model": os.getenv("EMBEDDING_MODEL", "BAAI/bge-small-en-v1.5"),
    "reranker_model": os.getenv("RERANKER_MODEL", "BAAI/bge-reranker-large"), 
    "qwen_model": "qwen-turbo",
    "qwen_api_key": os.getenv("QWEN_API_KEY"),
    "qwen_base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
    "index_dir": "./indexes",
     "log_dir": "./logs",
     "temp_dir": "./temp",
     "upload_dir": "./uploads",
    "top_k_retrieval": 20,
    "top_k_rerank": 5,
    "max_tokens": 1024,
    "temperature": 0.1
}

# é…ç½®æ—¥å¿—
logger.remove()
logger.add(
    sys.stderr,
    format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>",
    level="INFO"
)
logger.add(
    "logs/libchat.log",
    format="{time:YYYY-MM-DD HH:mm:ss} | {level: <8} | {name}:{function}:{line} - {message}",
    level="DEBUG",
    rotation="10 MB"
)


def ensure_directories() -> None:
    """ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨ã€‚"""
    Path(CONFIG["index_dir"]).mkdir(parents=True, exist_ok=True)
    Path(CONFIG["log_dir"]).mkdir(parents=True, exist_ok=True)
    Path(CONFIG["temp_dir"]).mkdir(parents=True, exist_ok=True)
    Path(CONFIG["upload_dir"]).mkdir(parents=True, exist_ok=True)


def process_query(query: str, index_path: str) -> str:
    """
    å¤„ç†ç”¨æˆ·æŸ¥è¯¢ï¼Œæ‰§è¡Œå®Œæ•´çš„GraphRAGæµç¨‹ã€‚
    
    Args:
        query: ç”¨æˆ·æŸ¥è¯¢
        index_path: ç´¢å¼•è·¯å¾„
        
    Returns:
        ç”Ÿæˆçš„ç­”æ¡ˆ
    """
    try:
        # 1. åŠ è½½å‘é‡ç´¢å¼•
        logger.info(f"æ­£åœ¨åŠ è½½å‘é‡ç´¢å¼•: {index_path}")
        indexer = FixedIndexer(index_dir=CONFIG["index_dir"])
        index_name = Path(index_path).name
        index = indexer.load_index(index_name, embedding_model=CONFIG["embedding_model"])
        
        if index is None:
            logger.error(f"æ— æ³•åŠ è½½ç´¢å¼•: {index_name}")
            return f"æŠ±æ­‰ï¼Œæ— æ³•åŠ è½½ç´¢å¼• '{index_name}'ã€‚è¯·ç¡®ä¿ç´¢å¼•å·²æ­£ç¡®æ„å»ºã€‚"
        
        # 2. åŠ è½½çŸ¥è¯†å›¾è°±
        graph_path = str(Path(index_path) / f"knowledge_graph_{index_name}.gpickle")
        logger.info(f"æ­£åœ¨åŠ è½½çŸ¥è¯†å›¾è°±: {graph_path}")
        
        try:
            knowledge_graph = load_knowledge_graph(graph_path)
        except Exception as e:
            logger.warning(f"åŠ è½½çŸ¥è¯†å›¾è°±å¤±è´¥: {e}ï¼Œå›é€€åˆ°åŸºç¡€å‘é‡æ£€ç´¢")
            # å›é€€åˆ°åŸå§‹çš„å‘é‡æ£€ç´¢æµç¨‹
            return _fallback_vector_retrieval(query, index)
        
        # 3. åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶
        logger.info("æ­£åœ¨åˆå§‹åŒ–æ£€ç´¢ç»„ä»¶...")
        
        # åŸºç¡€å‘é‡æ£€ç´¢å™¨
        vector_retriever = VectorIndexRetriever(
            index=index,
            similarity_top_k=CONFIG["top_k_retrieval"]
        )
        
        # é‡æ’åºå™¨
        reranker = SentenceTransformerReranker(
            model_name=CONFIG["reranker_model"],
            top_n=CONFIG["top_k_rerank"]
        )
        
        # GraphRAGæ£€ç´¢å™¨
        expansion_depth = CONFIG.get("expansion_depth", 1)
        graph_retriever = GraphRAGRetriever(
            vector_retriever=vector_retriever,
            knowledge_graph=knowledge_graph,
            reranker=reranker,
            expansion_depth=expansion_depth
        )
        
        # 4. æ‰§è¡ŒGraphRAGæ£€ç´¢
        logger.info(f"æ­£åœ¨æ‰§è¡ŒGraphRAGæ£€ç´¢: {query}")
        retrieved_nodes = graph_retriever.retrieve(query)
        
        if not retrieved_nodes:
            logger.warning("GraphRAGæ£€ç´¢æœªè¿”å›ç»“æœï¼Œå›é€€åˆ°åŸºç¡€å‘é‡æ£€ç´¢")
            return _fallback_vector_retrieval(query, index)
        
        logger.info(f"GraphRAGæ£€ç´¢å®Œæˆï¼Œè·å¾— {len(retrieved_nodes)} ä¸ªé«˜è´¨é‡ç»“æœ")
        
        # 5. æ„å»ºä¸Šä¸‹æ–‡
        context_texts = []
        for node in retrieved_nodes:
            if hasattr(node.node, 'text'):
                context_texts.append(node.node.text)
            elif hasattr(node, 'text'):
                context_texts.append(node.text)
        
        context = "\n\n".join(context_texts)
        
        # 5. ç”Ÿæˆç­”æ¡ˆ
        logger.info("æ­£åœ¨ç”Ÿæˆç­”æ¡ˆ...")
        answer = generate_answer_with_llm(query, context)
        
        return answer
        
    except Exception as e:
        logger.error(f"å¤„ç†æŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
        return f"å¤„ç†æŸ¥è¯¢æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"


def generate_answer_with_llm(query: str, context: str) -> str:
    """
    ä½¿ç”¨Qwen APIåŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆç­”æ¡ˆã€‚
    
    Args:
        query: ç”¨æˆ·æŸ¥è¯¢
        context: æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡
        
    Returns:
        ç”Ÿæˆçš„ç­”æ¡ˆ
    """
    try:
        # åˆå§‹åŒ–Qwenå®¢æˆ·ç«¯ï¼ˆä½¿ç”¨OpenAIå…¼å®¹æ¥å£ï¼‰
        client = OpenAI(
            api_key=CONFIG["qwen_api_key"],
            base_url=CONFIG["qwen_base_url"]
        )
        
        # æ„å»ºæ¶ˆæ¯
        messages = [
            {
                "role": "system",
                "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Pythonä»£ç åŠ©æ‰‹ã€‚è¯·åŸºäºæä¾›çš„ä»£ç ä¸Šä¸‹æ–‡å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚æä¾›å‡†ç¡®ã€è¯¦ç»†çš„ç­”æ¡ˆï¼Œå¦‚æœå¯èƒ½çš„è¯ï¼ŒåŒ…å«ç›¸å…³çš„ä»£ç ç¤ºä¾‹ã€‚å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰è¶³å¤Ÿçš„ä¿¡æ¯æ¥å›ç­”é—®é¢˜ï¼Œè¯·è¯šå®åœ°è¯´æ˜ã€‚"
            },
            {
                "role": "user",
                "content": f"""ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
                {context}

                ç”¨æˆ·é—®é¢˜ï¼š{query}

                è¯·åŸºäºä¸Šè¿°ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ã€‚"""
            }
        ]
        
        # æ‰“å°å®Œæ•´çš„æç¤ºè¯åˆ°æ—¥å¿—
        logger.info(f"æ„å»ºçš„æç¤ºè¯ï¼ˆPromptï¼‰: {json.dumps(messages, indent=2, ensure_ascii=False)}")

        # è°ƒç”¨Qwen API
        logger.info(f"æ­£åœ¨è°ƒç”¨Qwen API ({CONFIG['qwen_model']})...")
        response = client.chat.completions.create(
            model=CONFIG["qwen_model"],
            messages=messages,
            max_tokens=CONFIG["max_tokens"],
            temperature=CONFIG["temperature"]
        )
        
        answer = response.choices[0].message.content.strip()
        logger.info("Qwen APIè°ƒç”¨æˆåŠŸ")
        
        return answer if answer else "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•åŸºäºæä¾›çš„ä¸Šä¸‹æ–‡ç”Ÿæˆåˆé€‚çš„ç­”æ¡ˆã€‚"
        
    except Exception as e:
        error_msg = str(e)
        logger.error(f"Qwen APIè°ƒç”¨å¤±è´¥: {e}")
        logger.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
        logger.error(f"é”™è¯¯è¯¦æƒ…: {error_msg}")
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯é…é¢ä¸è¶³çš„é”™è¯¯
        if "429" in error_msg or "quota" in error_msg.lower() or "insufficient_quota" in error_msg.lower():
            logger.warning("Qwen APIé…é¢ä¸è¶³ï¼Œè¯·æ£€æŸ¥æ‚¨çš„è®¡è´¹è¯¦æƒ…")
            quota_msg = "\nâš ï¸  Qwen APIé…é¢ä¸è¶³æç¤ºï¼š\n" + \
                       "æ‚¨çš„Qwen APIé…é¢å·²ç”¨å®Œã€‚è¯·è®¿é—®é˜¿é‡Œäº‘æ§åˆ¶å°æ£€æŸ¥æ‚¨çš„è®¡è´¹è¯¦æƒ…ã€‚\n" + \
                       "ç°åœ¨å°†ä½¿ç”¨ç®€å•çš„åŸºäºæ£€ç´¢çš„ç­”æ¡ˆç”Ÿæˆã€‚\n"
            simple_answer = generate_simple_answer(query, context)
            return quota_msg + simple_answer
        
        logger.info("å›é€€åˆ°ç®€å•ç­”æ¡ˆç”Ÿæˆ...")
        return generate_simple_answer(query, context)


def generate_simple_answer(query: str, context: str) -> str:
    """
    å½“LLMä¸å¯ç”¨æ—¶çš„ç®€å•ç­”æ¡ˆç”Ÿæˆå¤‡ç”¨æ–¹æ¡ˆã€‚
    
    Args:
        query: ç”¨æˆ·æŸ¥è¯¢
        context: æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡
        
    Returns:
        åŸºäºæ£€ç´¢ç»“æœçš„ç®€å•ç­”æ¡ˆ
    """
    # ç®€å•çš„åŸºäºå…³é”®è¯åŒ¹é…çš„ç­”æ¡ˆç”Ÿæˆ
    lines = context.split('\n')
    relevant_lines = []
    
    query_words = query.lower().split()
    
    for line in lines:
        if any(word in line.lower() for word in query_words):
            relevant_lines.append(line.strip())
    
    if relevant_lines:
        answer = "åŸºäºæ£€ç´¢åˆ°çš„ä»£ç ï¼Œä»¥ä¸‹æ˜¯ç›¸å…³ä¿¡æ¯ï¼š\n\n"
        answer += "\n".join(relevant_lines[:5])  # é™åˆ¶æ˜¾ç¤ºå‰5è¡Œ
        if len(relevant_lines) > 5:
            answer += "\n\n...ï¼ˆè¿˜æœ‰æ›´å¤šç›¸å…³å†…å®¹ï¼‰"
    else:
        answer = "æŠ±æ­‰ï¼Œæˆ‘åœ¨æ£€ç´¢åˆ°çš„ä»£ç ä¸­æ²¡æœ‰æ‰¾åˆ°ä¸æ‚¨é—®é¢˜ç›´æ¥ç›¸å…³çš„ä¿¡æ¯ã€‚\n\næ£€ç´¢åˆ°çš„éƒ¨åˆ†å†…å®¹ï¼š\n\n"
        answer += context[:500] + "..." if len(context) > 500 else context
    
    return answer


@app.command("test", help="è¿è¡Œå®Œæ•´çš„ç«¯åˆ°ç«¯æµ‹è¯•")
def run_test(
    package_name: str = typer.Option("typer", "--package", "-p", help="ç”¨äºæµ‹è¯•çš„åŒ…å"),
    query: str = typer.Option("å¦‚ä½•åˆ›å»ºä¸€ä¸ªCLIåº”ç”¨ç¨‹åºï¼Ÿ", "--query", "-q", help="ç”¨äºæµ‹è¯•çš„æŸ¥è¯¢")
) -> None:
    """æ‰§è¡Œå®Œæ•´çš„ç«¯åˆ°ç«¯æµ‹è¯•ã€‚"""
    console = Console()
    console.print(Panel(f"[bold green]å¼€å§‹ç«¯åˆ°ç«¯æµ‹è¯•[/bold green]", title="æµ‹è¯•æµç¨‹", expand=False))
    
    # 1. å¼ºåˆ¶é‡å»ºç´¢å¼•
    test_index_name = "test_index"
    console.print(f"[cyan]æ­¥éª¤ 1: å¼ºåˆ¶é‡å»ºç´¢å¼• '{test_index_name}' (ä½¿ç”¨åŒ…: {package_name})[/cyan]")
    build_index(package_name, test_index_name, force_rebuild=True)
    
    # 2. ä½¿ç”¨æµ‹è¯•æŸ¥è¯¢æé—®
    console.print(f"[cyan]æ­¥éª¤ 2: ä½¿ç”¨æµ‹è¯•æŸ¥è¯¢æé—®[/cyan]")
    console.print(f"[yellow]æŸ¥è¯¢:[/yellow] {query}")
    ask_question(query, test_index_name)
    
    console.print(Panel(f"[bold green]ç«¯åˆ°ç«¯æµ‹è¯•å®Œæˆ[/bold green]", title="æµ‹è¯•æµç¨‹", expand=False))

@app.command("build-github", help="ä»GitHubä»“åº“æ„å»ºçŸ¥è¯†åº“ç´¢å¼•")
def build_github_index(
    github_url: str = typer.Argument(..., help="GitHubä»“åº“URL"),
    index_name: str = typer.Option(None, "--index", "-i", help="è¦åˆ›å»ºçš„ç´¢å¼•çš„åç§°ï¼ˆé»˜è®¤ä½¿ç”¨ä»“åº“åï¼‰"),
    force_rebuild: bool = typer.Option(False, "--force", "-f", help="å¼ºåˆ¶é‡æ–°æ„å»ºç´¢å¼•"),
    max_size_mb: int = typer.Option(100, "--max-size", "-s", help="ä»“åº“æœ€å¤§å¤§å°é™åˆ¶ï¼ˆMBï¼‰")
) -> None:
    """
    ä»GitHubä»“åº“æ„å»ºçŸ¥è¯†åº“ç´¢å¼•ã€‚
    
    è¯¥å‘½ä»¤ä¼šï¼š
    1. å…‹éš†æŒ‡å®šçš„GitHubä»“åº“
    2. åˆ†æä»“åº“ä¸­çš„æ‰€æœ‰ä»£ç æ–‡ä»¶
    3. ä½¿ç”¨å¤šè¯­è¨€åˆ†å—å™¨å¯¹ä»£ç è¿›è¡Œç»“æ„åŒ–åˆ†å—
    4. åˆ›å»ºå‘é‡ç´¢å¼•å¹¶ä¿å­˜åˆ°æœ¬åœ°
    
    Args:
        github_url: GitHubä»“åº“URL
        index_name: ç´¢å¼•åç§°ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨ä»“åº“åï¼‰
        force_rebuild: æ˜¯å¦å¼ºåˆ¶é‡æ–°æ„å»ºç´¢å¼•
        max_size_mb: ä»“åº“å¤§å°é™åˆ¶ï¼ˆMBï¼‰
    """
    console = Console()
    ensure_directories()

    try:
        # åˆå§‹åŒ–GitHubçˆ¬è™«
        crawler = GitHubCrawler(max_repo_size=max_size_mb)
        
        console.print(Panel.fit(
            f"[bold blue]å¼€å§‹ä»GitHubä»“åº“æ„å»ºçŸ¥è¯†åº“ç´¢å¼•[/bold blue]\n"
            f"ğŸ”— ä»“åº“URL: {github_url}",
            border_style="blue"
        ))

        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console
        ) as progress:
            # å…‹éš†ä»“åº“
            task_clone = progress.add_task("æ­£åœ¨å…‹éš†GitHubä»“åº“...", total=None)
            repo_info = crawler.clone_repository(github_url)
            
            if not repo_info:
                console.print("[red]é”™è¯¯ï¼šå…‹éš†ä»“åº“å¤±è´¥[/red]")
                raise typer.Exit(code=1)
            
            # å¦‚æœæ²¡æœ‰æŒ‡å®šç´¢å¼•åç§°ï¼Œä½¿ç”¨ä»“åº“å
            if not index_name:
                index_name = repo_info['name']
            
            progress.update(task_clone, description=f"ä»“åº“å…‹éš†å®Œæˆ - {repo_info['name']}")
            
            # åˆ†æä»£ç æ–‡ä»¶
            task_analyze = progress.add_task("æ­£åœ¨åˆ†æä»£ç æ–‡ä»¶...", total=None)
            analysis_result = crawler.analyze_repository(repo_info['local_path'])
            
            if not analysis_result or not analysis_result['chunks']:
                console.print("[red]é”™è¯¯ï¼šæœªæ‰¾åˆ°å¯åˆ†æçš„ä»£ç æ–‡ä»¶[/red]")
                raise typer.Exit(code=1)
            
            progress.update(task_analyze, description=f"ä»£ç åˆ†æå®Œæˆ - æ‰¾åˆ° {len(analysis_result['chunks'])} ä¸ªä»£ç å—")
            
            # æ„å»ºå‘é‡ç´¢å¼•
            task_build = progress.add_task("æ­£åœ¨æ„å»ºå‘é‡ç´¢å¼•...", total=None)
            
            index_dir = Path(CONFIG["index_dir"])
            indexer = FixedIndexer(index_dir=str(index_dir))
            
            # ä½¿ç”¨åˆ†æç»“æœæ„å»ºç´¢å¼•
            success = indexer.build_index_from_chunks(
                chunks=analysis_result['chunks'],
                index_name=index_name,
                embedding_model=CONFIG["embedding_model"],
                metadata={
                    'source_type': 'github',
                    'repository_url': github_url,
                    'repository_name': repo_info['name'],
                    'total_files': analysis_result['total_files'],
                    'supported_files': analysis_result['supported_files']
                }
            )
            
            if not success:
                console.print("[red]é”™è¯¯ï¼šæ„å»ºç´¢å¼•å¤±è´¥[/red]")
                raise typer.Exit(code=1)
            
            progress.update(task_build, description="å‘é‡ç´¢å¼•æ„å»ºå®Œæˆ")
            
            # æ„å»ºçŸ¥è¯†å›¾è°±ï¼ˆå¦‚æœæœ‰Pythonæ–‡ä»¶ï¼‰
            python_files = {f: content for f, content in analysis_result.get('file_contents', {}).items() 
                          if f.endswith('.py')}
            
            if python_files:
                task_kg = progress.add_task("æ­£åœ¨æ„å»ºçŸ¥è¯†å›¾è°±...", total=None)
                
                ast_chunker = ASTChunker()
                knowledge_graph = ast_chunker.create_knowledge_graph(python_files)
                
                # ä¿å­˜çŸ¥è¯†å›¾è°±
                final_index_path = index_dir / index_name
                final_index_path.mkdir(parents=True, exist_ok=True)
                graph_path = str(final_index_path / f"knowledge_graph_{index_name}.gpickle")
                save_knowledge_graph(knowledge_graph, graph_path)
                
                progress.update(task_kg, description=f"çŸ¥è¯†å›¾è°±æ„å»ºå®Œæˆ - èŠ‚ç‚¹: {len(knowledge_graph.nodes())}, è¾¹: {len(knowledge_graph.edges())}")

        console.print(Panel.fit(
            f"[bold green]âœ… æˆåŠŸä»GitHubä»“åº“æ„å»ºçŸ¥è¯†åº“ç´¢å¼•ï¼[/bold green]\n"
            f"ğŸ“ ç´¢å¼•åç§°: {index_name}\n"
            f"ğŸ”— æºä»“åº“: {github_url}\n"
            f"ğŸ“Š åˆ†ææ–‡ä»¶: {analysis_result['supported_files']}/{analysis_result['total_files']}\n"
            f"ğŸ“ å­˜å‚¨ä½ç½®: {index_dir / index_name}",
            border_style="green",
            title="æ„å»ºå®Œæˆ"
        ))
        
    except Exception as e:
        console.print(f"[red]æ„å»ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}[/red]")
        logger.error(f"GitHubç´¢å¼•æ„å»ºå¤±è´¥: {e}", exc_info=True)
        raise e


@app.command("build", help="æ„å»ºæŒ‡å®šPythonåº“çš„çŸ¥è¯†åº“ç´¢å¼•")
def build_index(
    package_name: str = typer.Argument(..., help="è¦ç´¢å¼•çš„PythonåŒ…çš„åç§°"),
    index_name: str = typer.Option("default", "--index", "-i", help="è¦åˆ›å»ºçš„ç´¢å¼•çš„åç§°"),
    force_rebuild: bool = typer.Option(False, "--force", "-f", help="å¼ºåˆ¶é‡æ–°æ„å»ºç´¢å¼•"),
    package_path: Optional[str] = typer.Option(None, "--path", "-p", help="æ‰‹åŠ¨æŒ‡å®šåŒ…çš„ç‰©ç†è·¯å¾„")
) -> None:
    """
    æ„å»ºæŒ‡å®šPythonåº“çš„çŸ¥è¯†åº“ç´¢å¼•ã€‚
    
    è¯¥å‘½ä»¤ä¼šï¼š
    1. æ£€æŸ¥å¹¶è·å–æŒ‡å®šåŒ…çš„æ‰€æœ‰æºæ–‡ä»¶
    2. ä½¿ç”¨ASTè§£æå™¨å¯¹æºä»£ç è¿›è¡Œç»“æ„åŒ–åˆ†å—
    3. åˆ›å»ºå‘é‡ç´¢å¼•å¹¶ä¿å­˜åˆ°æœ¬åœ°
    
    Args:
        package_name: PythonåŒ…åç§°ï¼ˆå¦‚ 'numpy', 'pandas' ç­‰ï¼‰
        force: æ˜¯å¦å¼ºåˆ¶é‡æ–°æ„å»ºç´¢å¼•
    """
    console = Console()
    ensure_directories()

    # ä½¿ç”¨åŒ…åä½œä¸ºä»£ç åº“è·¯å¾„
    repo_path = package_name
    index_dir = Path(CONFIG["index_dir"])

    console.print(Panel.fit(
        f"[bold blue]å¼€å§‹ä¸º '{repo_path}' æ„å»ºçŸ¥è¯†åº“ç´¢å¼• (åç§°: {index_name})[/bold blue]",
        border_style="blue"
    ))

    try:
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console
        ) as progress:
            # æ„å»ºçŸ¥è¯†å›¾è°±
            task_kg = progress.add_task("æ­£åœ¨æ„å»ºçŸ¥è¯†å›¾è°±...", total=None)
            logger.info(f"å¼€å§‹ä¸ºä»£ç åº“ '{repo_path}' æ„å»ºçŸ¥è¯†å›¾è°±")
            
            # è·å–æºæ–‡ä»¶
            inspector = PackageInspector(repo_path)
            source_files = inspector.get_source_files()
            
            if not source_files:
                console.print(f"[red]é”™è¯¯ï¼šæœªæ‰¾åˆ°åŒ… '{repo_path}' çš„æºæ–‡ä»¶[/red]")
                raise typer.Exit(code=1)
            
            # æ„å»ºçŸ¥è¯†å›¾è°±
            ast_chunker = ASTChunker()
            source_files_dict = {}
            
            for file_path in source_files:
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        file_content = f.read()
                        source_files_dict[str(file_path)] = file_content
                except Exception as e:
                    logger.warning(f"è¯»å–æ–‡ä»¶ {file_path} å¤±è´¥: {e}")
                    continue
            
            # åˆ›å»ºçŸ¥è¯†å›¾è°±
            knowledge_graph = ast_chunker.create_knowledge_graph(source_files_dict)
            
            # ä¿å­˜çŸ¥è¯†å›¾è°±
            final_index_path = index_dir / index_name
            final_index_path.mkdir(parents=True, exist_ok=True)  # ç¡®ä¿ç›®å½•å­˜åœ¨
            graph_path = str(final_index_path / f"knowledge_graph_{index_name}.gpickle")
            save_knowledge_graph(knowledge_graph, graph_path)
            
            progress.update(task_kg, description=f"çŸ¥è¯†å›¾è°±æ„å»ºå®Œæˆ - èŠ‚ç‚¹: {len(knowledge_graph.nodes())}, è¾¹: {len(knowledge_graph.edges())}")
            logger.info(f"çŸ¥è¯†å›¾è°±æ„å»ºå®Œæˆ - èŠ‚ç‚¹æ•°: {len(knowledge_graph.nodes())}, è¾¹æ•°: {len(knowledge_graph.edges())}")
            
            # æ„å»ºå‘é‡ç´¢å¼•
            task_build_index = progress.add_task("æ­£åœ¨åˆ›å»ºå¹¶æŒä¹…åŒ–å‘é‡ç´¢å¼•...", total=None)
            logger.info(f"å¼€å§‹ä¸ºä»£ç åº“ '{repo_path}' æ„å»ºç´¢å¼• '{index_name}'")

            indexer = FixedIndexer(index_dir=str(index_dir))

            # è°ƒç”¨ FixedIndexer çš„ rebuild_index æ–¹æ³•
            success = indexer.rebuild_index(
                repo_path, 
                index_name=index_name, 
                embedding_model=CONFIG["embedding_model"],
                package_path=package_path
            )

            if not success:
                console.print("[red]é”™è¯¯ï¼šæ„å»ºç´¢å¼•å¤±è´¥ã€‚[/red]")
                raise typer.Exit(code=1)

            progress.update(task_build_index, description="ç´¢å¼•åˆ›å»ºå®Œæˆ")
            final_index_path = index_dir / index_name
            logger.info(f"ç´¢å¼•å·²ä¿å­˜åˆ° {final_index_path}")

        console.print(Panel.fit(
            f"[bold green]âœ… æˆåŠŸä¸º '{repo_path}' æ„å»ºçŸ¥è¯†åº“ç´¢å¼•ï¼[/bold green]\n"
            f"ğŸ“ ç´¢å¼•åç§°: {index_name}\n"
            f"ğŸ“ å­˜å‚¨ä½ç½®: {final_index_path}",
            border_style="green",
            title="æ„å»ºå®Œæˆ"
        ))
        
    except Exception as e:
        console.print(f"[red]æ„å»ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}[/red]")
        logger.error(f"æ„å»ºç´¢å¼•å¤±è´¥: {e}", exc_info=True)
        raise e


def _fallback_vector_retrieval(query: str, index) -> str:
    """
    å½“GraphRAGæ£€ç´¢å¤±è´¥æ—¶çš„å›é€€æ–¹æ¡ˆï¼Œä½¿ç”¨åŸºç¡€å‘é‡æ£€ç´¢
    
    Args:
        query: ç”¨æˆ·æŸ¥è¯¢
        index: å‘é‡ç´¢å¼•
        
    Returns:
        ç”Ÿæˆçš„ç­”æ¡ˆ
    """
    logger.info("æ‰§è¡Œå›é€€å‘é‡æ£€ç´¢æµç¨‹")
    
    try:
        # åŸºç¡€å‘é‡æ£€ç´¢
        retriever = VectorIndexRetriever(
            index=index,
            similarity_top_k=CONFIG["top_k_retrieval"]
        )
        retrieved_nodes = retriever.retrieve(query)
        
        if not retrieved_nodes:
            return "æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰æ‰¾åˆ°ä¸æ‚¨çš„é—®é¢˜ç›¸å…³çš„ä¿¡æ¯ã€‚"
        
        # é‡æ’åºï¼ˆå¦‚æœæœ‰è¶³å¤Ÿçš„æ–‡æ¡£ï¼‰
        if len(retrieved_nodes) > CONFIG["top_k_rerank"]:
            reranker = SentenceTransformerReranker(
                model_name=CONFIG["reranker_model"],
                top_n=CONFIG["top_k_rerank"]
            )
            
            documents = [node.text for node in retrieved_nodes]
            reranked_docs = reranker.rerank(query, documents)
            context_texts = reranked_docs
        else:
            context_texts = [node.text for node in retrieved_nodes]
        
        context = "\n\n".join(context_texts)
        
        # ç”Ÿæˆç­”æ¡ˆ
        answer = generate_answer_with_llm(query, context)
        return answer
        
    except Exception as e:
        logger.error(f"å›é€€æ£€ç´¢ä¹Ÿå¤±è´¥: {e}")
        return f"æŠ±æ­‰ï¼Œæ£€ç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"


@app.command("ask", help="åŸºäºæ„å»ºçš„çŸ¥è¯†åº“å›ç­”ç”¨æˆ·é—®é¢˜")
def ask_question(
    query: str = typer.Argument(..., help="æ‚¨è¦æå‡ºçš„é—®é¢˜"),
    index_name: str = typer.Option("default", "--index", "-i", help="è¦ä½¿ç”¨çš„ç´¢å¼•åç§°"),
    expansion_depth: int = typer.Option(1, "--depth", "-d", help="å›¾éå†æ‰©å±•æ·±åº¦")
) -> None:
    """
    å¤„ç†ç”¨æˆ·æŸ¥è¯¢å¹¶æ‰“å°ç­”æ¡ˆï¼Œä½¿ç”¨GraphRAGå¢å¼ºæ£€ç´¢ã€‚
    
    Args:
        query: ç”¨æˆ·é—®é¢˜
        index_name: è¦ä½¿ç”¨çš„ç´¢å¼•åç§°
        expansion_depth: çŸ¥è¯†å›¾è°±éå†çš„æ‰©å±•æ·±åº¦
    """
    console = Console()
    ensure_directories()
    index_path = Path(CONFIG["index_dir"]) / index_name
    graph_path = index_path / f"knowledge_graph_{index_name}.gpickle"

    # æ£€æŸ¥ç´¢å¼•æ˜¯å¦å­˜åœ¨
    if not index_path.exists():
        console.print(f"[red]é”™è¯¯ï¼šç´¢å¼• '{index_name}' ä¸å­˜åœ¨ã€‚è¯·å…ˆä½¿ç”¨ 'build' å‘½ä»¤æ„å»ºå®ƒã€‚[/red]")
        raise typer.Exit(code=1)
    
    # æ£€æŸ¥çŸ¥è¯†å›¾è°±æ˜¯å¦å­˜åœ¨
    if not Path(graph_path).exists():
        console.print(f"[yellow]è­¦å‘Šï¼šçŸ¥è¯†å›¾è°±æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†ä½¿ç”¨åŸºç¡€å‘é‡æ£€ç´¢ã€‚[/yellow]")
        console.print(f"[yellow]å»ºè®®é‡æ–°è¿è¡Œ 'build' å‘½ä»¤ä»¥ç”ŸæˆçŸ¥è¯†å›¾è°±ã€‚[/yellow]")

    console.print(Panel.fit(
        f"[bold blue]æ­£åœ¨ä½¿ç”¨GraphRAGå¢å¼ºæ£€ç´¢å›ç­”é—®é¢˜[/bold blue]\n"
        f"ğŸ“Š ç´¢å¼•: {index_name}\n"
        f"ğŸ•¸ï¸ å›¾éå†æ·±åº¦: {expansion_depth}",
        border_style="blue",
        title="GraphRAGæ£€ç´¢"
    ))

    try:
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console
        ) as progress:
            task_load = progress.add_task("æ­£åœ¨åŠ è½½ç´¢å¼•å’ŒçŸ¥è¯†å›¾è°±...", total=None)
            
            # ä¸´æ—¶æ›´æ–°é…ç½®ä¸­çš„æ‰©å±•æ·±åº¦
            original_depth = CONFIG.get("expansion_depth", 1)
            CONFIG["expansion_depth"] = expansion_depth
            
            try:
                answer = process_query(query, str(index_path))
                progress.update(task_load, description="GraphRAGæ£€ç´¢å®Œæˆ")
            finally:
                # æ¢å¤åŸå§‹é…ç½®
                CONFIG["expansion_depth"] = original_depth
        
        # æ˜¾ç¤ºç»“æœ
        console.print("\n" + "="*60)
        console.print(Markdown(f"**ğŸ¤” ä½ é—®**ï¼š{query}\n\n**ğŸ¤– å›ç­”**ï¼š{answer}"))
        console.print("="*60)
        
    except Exception as e:
        console.print(f"[red]å¤„ç†æŸ¥è¯¢æ—¶å‘ç”Ÿé”™è¯¯: {e}[/red]")
        logger.error(f"æŸ¥è¯¢å¤„ç†å¤±è´¥: {e}", exc_info=True)

if __name__ == "__main__":
    app()